{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "import random\n",
    "from kaggle_environments import evaluate, make\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "!pip install \"stable-baselines3\"\n",
    "from stable_baselines3 import PPO \n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from gym import spaces"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ConnectFourGym(gym.Env):\n",
    "    def __init__(self, agent2=\"random\"):\n",
    "        ks_env = make(\"connectx\", debug=True)\n",
    "        self.env = ks_env.train([None, agent2])\n",
    "        self.rows = ks_env.configuration.rows\n",
    "        self.columns = ks_env.configuration.columns\n",
    "        # Learn about spaces here: http://gym.openai.com/docs/#spaces\n",
    "        self.action_space = spaces.Discrete(self.columns)\n",
    "        self.observation_space = spaces.Box(low=0, high=2, \n",
    "                                            shape=(1,self.rows,self.columns), dtype=int)\n",
    "        # Tuple corresponding to the min and max possible rewards\n",
    "        self.reward_range = (-10, 1)\n",
    "        # StableBaselines throws error if these are not defined\n",
    "        self.spec = None\n",
    "        self.metadata = None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.obs = self.env.reset()\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns)\n",
    "    \n",
    "    def change_reward(self, old_reward, done):\n",
    "        if old_reward == 1: # The agent won the game\n",
    "            return 1\n",
    "        elif done: # The opponent won the game\n",
    "            return -1\n",
    "        else: # Reward 1/42\n",
    "            return 1/(self.rows*self.columns)\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Check if agent's move is valid\n",
    "        is_valid = (self.obs['board'][int(action)] == 0)\n",
    "        if is_valid: # Play the move\n",
    "            self.obs, old_reward, done, _ = self.env.step(int(action))\n",
    "            reward = self.change_reward(old_reward, done)\n",
    "        else: # End the game and penalize agent\n",
    "            reward, done, _ = -10, True, {}\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns), reward, done, _\n",
    "    \n",
    "# Create ConnectFour environment \n",
    "#env = ConnectFourGym(agent2=\"random\")\n",
    "env = ConnectFourGym(agent2=\"negamax\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Neural network for predicting action values\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int=128):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # CxHxW images (channels first)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with th.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                th.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    ")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize agent\n",
    "deep_rl_model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=0)\n",
    "\n",
    "# Train agent\n",
    "deep_rl_model.learn(total_timesteps=100000)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def trained_nn_agent(observation, config = {'rows': 6, 'columns': 7, 'inarow': 4}):\n",
    "    \"\"\"\n",
    "    Calculate next move based on neural network prediction\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observation: numpy.ndarray\n",
    "        A ``numpy.ndarray`` representing empty game board\n",
    "    config: dict of {str: int}\n",
    "        A dictionary with configuration parameters. Normally, it's passed to the\n",
    "        agent by the environment.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    action: int\n",
    "        Number representing the column chosen by the agent \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "        \n",
    "    observation = np.array(\n",
    "        observation['board']\n",
    "    ).reshape(1, config['rows'], config['columns'])\n",
    "    action, info = deep_rl_model.predict(observation)\n",
    "    \n",
    "    return int(action)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Returns True if dropping piece in column results in game win\n",
    "def check_winning_move(obs, config, col, piece):\n",
    "    # Convert the board to a 2D grid\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    next_grid = drop_piece(grid, col, piece, config)\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(next_grid[row,col:col+config.inarow])\n",
    "            if window.count(piece) == config.inarow:\n",
    "                return True\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(next_grid[row:row+config.inarow,col])\n",
    "            if window.count(piece) == config.inarow:\n",
    "                return True\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(next_grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if window.count(piece) == config.inarow:\n",
    "                return True\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(next_grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if window.count(piece) == config.inarow:\n",
    "                return True\n",
    "    return False"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-26T09:21:16.185745Z",
     "iopub.execute_input": "2023-02-26T09:21:16.186149Z",
     "iopub.status.idle": "2023-02-26T09:21:16.221570Z",
     "shell.execute_reply.started": "2023-02-26T09:21:16.186112Z",
     "shell.execute_reply": "2023-02-26T09:21:16.220369Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define player for round\n",
    "def agent_q1(obs, config):\n",
    "    # Returns True if dropping piece in column results in game win\n",
    "    def check_winning_move(obs, config, col, piece):\n",
    "        # Convert the board to a 2D grid\n",
    "        grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "        next_grid = drop_piece(grid, col, piece, config)\n",
    "        # horizontal\n",
    "        for row in range(config.rows):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(next_grid[row,col:col+config.inarow])\n",
    "                if window.count(piece) == config.inarow:\n",
    "                    return True\n",
    "        # vertical\n",
    "        for row in range(config.rows-(config.inarow-1)):\n",
    "            for col in range(config.columns):\n",
    "                window = list(next_grid[row:row+config.inarow,col])\n",
    "                if window.count(piece) == config.inarow:\n",
    "                    return True\n",
    "        # positive diagonal\n",
    "        for row in range(config.rows-(config.inarow-1)):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(next_grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "                if window.count(piece) == config.inarow:\n",
    "                    return True\n",
    "        # negative diagonal\n",
    "        for row in range(config.inarow-1, config.rows):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(next_grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "                if window.count(piece) == config.inarow:\n",
    "                    return True\n",
    "        return False\n",
    "    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n",
    "    # Amend the agent!\n",
    "    for col in valid_moves:\n",
    "        if check_winning_move(obs, config, col, obs.mark):\n",
    "            return col\n",
    "    return random.choice(valid_moves)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the game environment\n",
    "env = make(\"connectx\", debug=True)\n",
    "\n",
    "# Two random agents play one game round\n",
    "obs = env.run([agent_q1, trained_nn_agent])\n",
    "\n",
    "# Show the game\n",
    "env.render(mode=\"ipython\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def my_agent(obs, config):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    \n",
    "    def drop_piece(grid, col, mark, config):\n",
    "        next_grid = grid.copy()\n",
    "        for row in range(config.rows-1, -1, -1):\n",
    "            if next_grid[row][col] == 0:\n",
    "                break\n",
    "        next_grid[row][col] = mark\n",
    "        return next_grid\n",
    "\n",
    "    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n",
    "    def check_window(window, num_discs, piece, config):\n",
    "        return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n",
    "\n",
    "    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n",
    "    def count_windows(grid, num_discs, piece, config):\n",
    "        num_windows = 0\n",
    "        # horizontal\n",
    "        for row in range(config.rows):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(grid[row, col:col+config.inarow])\n",
    "                if check_window(window, num_discs, piece, config):\n",
    "                    num_windows += 1\n",
    "        # vertical\n",
    "        for row in range(config.rows-(config.inarow-1)):\n",
    "            for col in range(config.columns):\n",
    "                window = list(grid[row:row+config.inarow, col])\n",
    "                if check_window(window, num_discs, piece, config):\n",
    "                    num_windows += 1\n",
    "        # positive diagonal\n",
    "        for row in range(config.rows-(config.inarow-1)):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "                if check_window(window, num_discs, piece, config):\n",
    "                    num_windows += 1\n",
    "        # negative diagonal\n",
    "        for row in range(config.inarow-1, config.rows):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "                if check_window(window, num_discs, piece, config):\n",
    "                    num_windows += 1\n",
    "        return num_windows\n",
    "    \n",
    "    # Helper function for minimax: calculates value of heuristic for grid\n",
    "    def get_heuristic(grid, mark, config):\n",
    "        num_threes = count_windows(grid, 3, mark, config)\n",
    "        num_fours = count_windows(grid, 4, mark, config)\n",
    "        num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n",
    "        num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n",
    "        score = num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp + 1e6*num_fours\n",
    "        return score\n",
    "    \n",
    "    # Uses minimax to calculate value of dropping piece in selected column\n",
    "    def score_move(grid, col, mark, config, nsteps):\n",
    "        next_grid = drop_piece(grid, col, mark, config)\n",
    "        score = minimax(next_grid, nsteps-1, False, mark, config)\n",
    "        return score\n",
    "\n",
    "    # Helper function for minimax: checks if agent or opponent has four in a row in the window\n",
    "    def is_terminal_window(window, config):\n",
    "        return window.count(1) == config.inarow or window.count(2) == config.inarow\n",
    "\n",
    "    # Helper function for minimax: checks if game has ended\n",
    "    def is_terminal_node(grid, config):\n",
    "        # Check for draw \n",
    "        if list(grid[0, :]).count(0) == 0:\n",
    "            return True\n",
    "        # Check for win: horizontal, vertical, or diagonal \n",
    "        for row in range(config.rows):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(grid[row, col:col+config.inarow])\n",
    "                if is_terminal_window(window, config):\n",
    "                    return True\n",
    "        # vertical\n",
    "        for row in range(config.rows-(config.inarow-1)):\n",
    "            for col in range(config.columns):\n",
    "                window = list(grid[row:row+config.inarow, col])\n",
    "                if is_terminal_window(window, config):\n",
    "                    return True\n",
    "        # positive diagonal\n",
    "        for row in range(config.rows-(config.inarow-1)):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "                if is_terminal_window(window, config):\n",
    "                    return True\n",
    "        # negative diagonal\n",
    "        for row in range(config.inarow-1, config.rows):\n",
    "            for col in range(config.columns-(config.inarow-1)):\n",
    "                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "                if is_terminal_window(window, config):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Minimax implementation\n",
    "    def minimax(node, depth, maximizingPlayer, mark, config, alpha=-1000, beta=1000):\n",
    "        is_terminal = is_terminal_node(node, config)\n",
    "        valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n",
    "        if depth == 0 or is_terminal:\n",
    "            return get_heuristic(node, mark, config)\n",
    "        if maximizingPlayer:\n",
    "            best = MIN\n",
    "            value = -np.Inf\n",
    "            for col in valid_moves:\n",
    "                child = drop_piece(node, col, mark, config)\n",
    "                value = max(value, minimax(child, depth-1, False, mark, config))\n",
    "                best = max(best, value)\n",
    "                alpha = max(alpha, best)\n",
    "                \n",
    "                # Alpha Beta Pruning\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "          \n",
    "            return value\n",
    "        else:\n",
    "            best = MAX\n",
    "            value = np.Inf\n",
    "            for col in valid_moves:\n",
    "                child = drop_piece(node, col, mark%2+1, config)\n",
    "                value = min(value, minimax(child, depth-1, True, mark, config))\n",
    "                best = min(best, value)\n",
    "                beta = min(beta, best)\n",
    "                \n",
    "                # Alpha Beta Pruning\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return value\n",
    "    \n",
    "    MAX, MIN = 1000, -1000\n",
    "    N_STEPS = 3\n",
    "    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n",
    "    \n",
    "    # Convert the board to a 2D grid\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    \n",
    "    # Use the heuristic to assign a score to each possible board in the next step\n",
    "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config, N_STEPS) for col in valid_moves]))\n",
    "    \n",
    "    # Get a list of columns (moves) that maximize the heuristic\n",
    "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
    "    \n",
    "    # Select at random from the maximizing columns\n",
    "    return random.choice(max_cols)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-26T09:25:32.777607Z",
     "iopub.execute_input": "2023-02-26T09:25:32.778169Z",
     "iopub.status.idle": "2023-02-26T09:25:32.809821Z",
     "shell.execute_reply.started": "2023-02-26T09:25:32.778117Z",
     "shell.execute_reply": "2023-02-26T09:25:32.808670Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_agent(\n",
    "    agent1,\n",
    "    agent2,\n",
    "    config = {'rows': 6, 'columns': 7, 'inarow': 4},\n",
    "    num_episodes = 100\n",
    "):\n",
    "    # Agent 1 goes first (roughly) half the time          \n",
    "    outcomes = evaluate(\n",
    "        environment = \"connectx\",\n",
    "        agents = [agent1, agent2],\n",
    "        configuration = config,\n",
    "        num_episodes = num_episodes // 2\n",
    "    )\n",
    "\n",
    "    # Agent 2 goes first (roughly) half the time      \n",
    "    outcomes += [\n",
    "        [b,a] for [a,b] in evaluate(\n",
    "            environment = \"connectx\",\n",
    "            agents = [agent2, agent1],\n",
    "            configuration = config,\n",
    "            num_episodes = num_episodes -  num_episodes // 2\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"Agent 1 Win Percentage:\",np.round(outcomes.count([1,-1])/len(outcomes), 2))\n",
    "    print(\"Agent 2 Win Percentage:\",np.round(outcomes.count([-1,1])/len(outcomes), 2))\n",
    "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
    "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))\n",
    "\n",
    "print('Trained agent vs Random')\n",
    "evaluate_agent(trained_nn_agent, 'random')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# This may take a while\n",
    "print('Trained agent vs Heuristic')\n",
    "evaluate_agent(trained_nn_agent, my_agent)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('Trained model network:\\n')\n",
    "print(deep_rl_model.policy.state_dict().keys())\n",
    "\n",
    "state_dict = deep_rl_model.policy.to('cpu').state_dict()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def write_agent_to_file(function, file):\n",
    "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
    "        f.write(f'state_dict = {state_dict}\\n')\n",
    "#         print(function, \"written to\", f)\n",
    "\n",
    "state_dict = deep_rl_model.policy.to('cpu').state_dict()\n",
    "write_agent_to_file(state_dict , \"/kaggle/working/submission.py\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
